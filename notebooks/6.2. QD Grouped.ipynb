{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bananas.dataset import DataSet, DataType, Feature\n",
    "\n",
    "# Root path of project relative to this notebook\n",
    "ROOT = Path('..')\n",
    "\n",
    "sys.path.insert(1, str(ROOT / 'scripts'))\n",
    "from datamodels import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read subject data from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT / 'datasets' / 'subject_drawings_grouped.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load custom MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quick_draw_learner import QDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n",
    "\n",
    "target_label = 'SANO'\n",
    "target_column = 'diagnosis'\n",
    "category_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Define all possible hyperparameters\n",
    "kernel_sizes = [3, 5, 7, 9]\n",
    "batch_sizes = [24, 32, 48]\n",
    "test_splits = [.2, .25]\n",
    "validation_splits = [.2, .25]\n",
    "#max_skip_cats = 2  # Skip up to 2 drawing categories\n",
    "#skip_cats_combos = sum([list(combinations(category_columns, i))\n",
    "#                        for i in range(max_skip_cats)], [])\n",
    "\n",
    "# Initialize random number generator without seed to randomize hyperparamters\n",
    "rnd = np.random.RandomState()\n",
    "\n",
    "# Cross product all hyperparameters\n",
    "parameter_combinations = list(product(\n",
    "    kernel_sizes, batch_sizes, test_splits, validation_splits))\n",
    "rnd.shuffle(parameter_combinations)\n",
    "\n",
    "category_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bananas.sampling.cross_validation import DataSplit\n",
    "from bananas.statistics import scoring\n",
    "from bananas.statistics.scoring import ScoringFunction\n",
    "\n",
    "# Store results in a list to display them later\n",
    "trial_results = []\n",
    "\n",
    "# Perform 3 trials per parameter set to later compute the average\n",
    "trial_count = 3\n",
    "\n",
    "for kernel_size, batch_size, test_split, validation_split in tqdm(parameter_combinations, leave=False):\n",
    "\n",
    "    # Re-initialize seed every time\n",
    "    random_seed = 0\n",
    "    \n",
    "    # Execute the independent trials\n",
    "    for _ in tqdm(range(trial_count), leave=False, desc='Trial'):\n",
    "\n",
    "        # Create a single feature containing all image data\n",
    "        #cats = [cat for cat in category_columns if ('processed_path_%s' % cat) not in skip_cats]\n",
    "        cats = category_columns\n",
    "        features = [Feature(\n",
    "            ImageAugmenterMultiLoader(df[cats].values),\n",
    "            kind=DataType.HIGH_DIMENSIOAL,\n",
    "            sample_size=10,\n",
    "            random_seed=random_seed)]\n",
    "\n",
    "        # Define target feature\n",
    "        target_feature = Feature(\n",
    "            (df[target_column] == target_label).values, random_seed=random_seed)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Build dataset, making sure that we have a left-out validation subset\n",
    "            dataset = DataSet(\n",
    "                features,\n",
    "                name=target_label,\n",
    "                target=target_feature,\n",
    "                random_seed=random_seed,\n",
    "                batch_size=batch_size,\n",
    "                test_split=test_split,\n",
    "                validation_split=validation_split)\n",
    "\n",
    "            # Compute test class balance to tell what minimum accuracy we should beat\n",
    "            test_idx = dataset.sampler.subsamplers[DataSplit.VALIDATION].data\n",
    "            test_classes = target_feature[test_idx]\n",
    "            test_class_balance = sum(test_classes) / len(test_classes)\n",
    "\n",
    "            # Rebuild dataset unless test class balance is within 5% of ground truth\n",
    "            true_class_balance = sum(target_feature[:] / len(target_feature))\n",
    "            if abs(test_class_balance - true_class_balance) < .05: break\n",
    "\n",
    "            # Keep changing the seed to avoid getting stuck\n",
    "            random_seed += 1\n",
    "\n",
    "        # Instantiate learner using pre-trained model\n",
    "        learner = QDClassifier(\n",
    "            kernel_size=5,\n",
    "            input_channel_count=len(cats),\n",
    "            random_seed=random_seed, verbose=False)\n",
    "\n",
    "        # Train learner using train dataset\n",
    "        learner.train(dataset.input_fn, progress=True, max_steps=1000)\n",
    "\n",
    "        # Test learner predictions using left-out validation dataset\n",
    "        X, y = dataset[test_idx]\n",
    "        y = learner.label_encoder_.transform(y)\n",
    "        y_ = learner.predict_proba(X)\n",
    "        score_auroc = scoring.score_auroc(y, y_)\n",
    "        score_accuracy = scoring.score_accuracy(y, y_)\n",
    "        score_precision = scoring.score_precision(y, y_)\n",
    "        score_recall = scoring.score_recall(y, y_)\n",
    "\n",
    "        # Store trial results\n",
    "        naive_accuracy = max(test_class_balance, 1 - test_class_balance)\n",
    "        trial_results.append({\n",
    "            'Subset splits': (test_split, validation_split),\n",
    "            'Kernel size': kernel_size,\n",
    "            #'Skipped categories': ', '.join(skip_cats),\n",
    "            'Batch size': batch_size,\n",
    "            'Î” Naive Classifier': score_accuracy - naive_accuracy,\n",
    "            'Accuracy': score_accuracy,\n",
    "            'Precision': score_precision,\n",
    "            'Recall': score_recall,\n",
    "            'Area under ROC': score_auroc,\n",
    "        })\n",
    "        \n",
    "        # Change seed to ensure different dataset split\n",
    "        random_seed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_records(trial_results).sort_values('Accuracy', ascending=False)\n",
    "res.to_csv('qd_grouped_results.csv')\n",
    "res.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
