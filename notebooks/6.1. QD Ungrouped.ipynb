{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bananas.utils import images\n",
    "from bananas.utils.arrays import unique\n",
    "from bananas.dataset import DataSet, DataType, Feature\n",
    "\n",
    "# Root path of project relative to this notebook\n",
    "ROOT = Path('..')\n",
    "\n",
    "sys.path.insert(1, str(ROOT / 'scripts'))\n",
    "from datamodels import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read patient data from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT / 'datasets' / 'subject_diagnosis.csv', index_col=0)\n",
    "\n",
    "# Convert non-primitive fields\n",
    "df['processed_path'] = df['processed_path'].apply(lambda x: Path(x))\n",
    "df['image_path'] = df['image_path'].apply(lambda x: Path(x))\n",
    "df['template_path'] = df['template_path'].apply(lambda x: Path(x))\n",
    "df['drawing_box'] = df['drawing_box'].apply(lambda x: Box.load(x))\n",
    "df['template_box'] = df['template_box'].apply(lambda x: Box.load(x))\n",
    "\n",
    "# Remove all unnecessary columns from our dataset\n",
    "feat_keys = ['processed_path']\n",
    "group_columns = ['diagnosis']\n",
    "df = df[group_columns + feat_keys].copy()\n",
    "\n",
    "# Normalize all feature columns\n",
    "df = df.dropna()\n",
    "for col in feat_keys:\n",
    "    df[col] = df[col].apply(lambda x: str(ROOT / x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load custom MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quick_draw_learner import QDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n",
    "    \n",
    "# Define all possible hyperparameters\n",
    "kernel_sizes = [3, 5, 7, 9]\n",
    "batch_sizes = [24, 32, 48]\n",
    "test_splits = [.2, .25]\n",
    "validation_splits = [.2, .25]\n",
    "\n",
    "# Initialize random number generator without seed to randomize hyperparamters\n",
    "rnd = np.random.RandomState()\n",
    "\n",
    "# Cross product all hyperparameters\n",
    "parameter_combinations = list(product(\n",
    "    kernel_sizes, batch_sizes, test_splits, validation_splits))\n",
    "rnd.shuffle(parameter_combinations)\n",
    "\n",
    "target_label = 'SANO'\n",
    "target_column = 'diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bananas.sampling.cross_validation import DataSplit\n",
    "from bananas.statistics import scoring\n",
    "from bananas.statistics.scoring import ScoringFunction\n",
    "\n",
    "# Store results in a list to display them later\n",
    "trial_results = []\n",
    "\n",
    "# Perform 3 trials per parameter set to later compute the average\n",
    "trial_count = 3\n",
    "\n",
    "for kernel_size, batch_size, test_split, validation_split in tqdm(parameter_combinations, leave=False):\n",
    "\n",
    "    # Re-initialize seed every time\n",
    "    random_seed = 0\n",
    "    \n",
    "    # Execute the independent trials\n",
    "    for _ in tqdm(range(trial_count), leave=False, desc='Trial'):\n",
    "\n",
    "        # Create a single feature containing all image data\n",
    "        features = [Feature(\n",
    "            ImageAugmenterLoader(df['processed_path'].values),\n",
    "            kind=DataType.HIGH_DIMENSIOAL,\n",
    "            sample_size=10,\n",
    "            random_seed=random_seed)]\n",
    "\n",
    "        # Define target feature\n",
    "        target_feature = Feature(\n",
    "            (df[target_column] == target_label).values, random_seed=random_seed)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Build dataset, making sure that we have a left-out validation subset\n",
    "            dataset = DataSet(\n",
    "                features,\n",
    "                name=target_label,\n",
    "                target=target_feature,\n",
    "                random_seed=random_seed,\n",
    "                batch_size=batch_size,\n",
    "                test_split=test_split,\n",
    "                validation_split=validation_split)\n",
    "\n",
    "            # Compute test class balance to tell what minimum accuracy we should beat\n",
    "            test_idx = dataset.sampler.subsamplers[DataSplit.VALIDATION].data\n",
    "            test_classes = target_feature[test_idx]\n",
    "            test_class_balance = sum(test_classes) / len(test_classes)\n",
    "\n",
    "            # Rebuild dataset unless test class balance is within 5% of ground truth\n",
    "            true_class_balance = sum(target_feature[:] / len(target_feature))\n",
    "            if abs(test_class_balance - true_class_balance) < .05: break\n",
    "\n",
    "            # Keep changing the seed to avoid getting stuck\n",
    "            random_seed += 1\n",
    "\n",
    "        # Instantiate learner\n",
    "        learner = QDClassifier(\n",
    "            kernel_size=kernel_size,\n",
    "            random_seed=random_seed, \n",
    "            verbose=False)\n",
    "\n",
    "        # Train learner using train dataset\n",
    "        learner.train(dataset.input_fn, progress=True, max_steps=1000)\n",
    "\n",
    "        # Test learner predictions using left-out dataset\n",
    "        X, y = dataset[test_idx]\n",
    "        y = learner.label_encoder_.transform(y)\n",
    "        y_ = learner.predict_proba(X)\n",
    "        score_auroc = scoring.score_auroc(y, y_)\n",
    "        score_accuracy = scoring.score_accuracy(y, y_)\n",
    "\n",
    "        # Store trial results\n",
    "        naive_accuracy = max(test_class_balance, 1 - test_class_balance)\n",
    "        trial_results.append({\n",
    "            'Subset Splits': (test_split, validation_split),\n",
    "            'Kernel size': kernel_size,\n",
    "            'Batch size': batch_size,\n",
    "            'Î” Naive Classifier': score_accuracy - naive_accuracy,\n",
    "            'Accuracy': score_accuracy,\n",
    "            'Area under ROC': score_auroc,\n",
    "        })\n",
    "        \n",
    "        # Change seed to ensure different dataset split\n",
    "        random_seed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame.from_records(trial_results).sort_values('Accuracy', ascending=False)\n",
    "res.to_csv('qd_ungrouped_results.csv')\n",
    "res.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
