{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import models as torchvision_models\n",
    "\n",
    "from bananas.training.criteria import HaltCriteria\n",
    "from bananas.dataset import DataSet, DataType, Feature\n",
    "\n",
    "# Root path of project relative to this notebook\n",
    "ROOT = Path('..')\n",
    "\n",
    "sys.path.insert(1, str(ROOT / 'scripts'))\n",
    "from datamodels import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained models to be used as starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34_model = torchvision_models.resnet34(pretrained=True)\n",
    "googlenet_model = torchvision_models.googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read subject data from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>processed_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002_1</th>\n",
       "      <td>SANO</td>\n",
       "      <td>../processed/muellePsic_002Ev1.pdf_pg-16.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_1</th>\n",
       "      <td>SANO</td>\n",
       "      <td>../processed/casaPsic_002Ev1.pdf_pg-18.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_1</th>\n",
       "      <td>SANO</td>\n",
       "      <td>../processed/minimentalPsic_002Ev1.pdf_pg-3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_1</th>\n",
       "      <td>SANO</td>\n",
       "      <td>../processed/picoPsic_002Ev1.pdf_pg-16.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_1</th>\n",
       "      <td>SANO</td>\n",
       "      <td>../processed/cruzPsic_002Ev1.pdf_pg-17.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      diagnosis                                   processed_path\n",
       "key                                                             \n",
       "002_1      SANO     ../processed/muellePsic_002Ev1.pdf_pg-16.jpg\n",
       "002_1      SANO       ../processed/casaPsic_002Ev1.pdf_pg-18.jpg\n",
       "002_1      SANO  ../processed/minimentalPsic_002Ev1.pdf_pg-3.jpg\n",
       "002_1      SANO       ../processed/picoPsic_002Ev1.pdf_pg-16.jpg\n",
       "002_1      SANO       ../processed/cruzPsic_002Ev1.pdf_pg-17.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ROOT / 'datasets' / 'subject_diagnosis.csv', index_col=0)\n",
    "\n",
    "# Convert non-primitive fields\n",
    "df['processed_path'] = df['processed_path'].apply(lambda x: Path(x))\n",
    "df['image_path'] = df['image_path'].apply(lambda x: Path(x))\n",
    "df['template_path'] = df['template_path'].apply(lambda x: Path(x))\n",
    "df['drawing_box'] = df['drawing_box'].apply(lambda x: Box.load(x))\n",
    "df['template_box'] = df['template_box'].apply(lambda x: Box.load(x))\n",
    "\n",
    "# Remove all unnecessary columns from our dataset\n",
    "feat_keys = ['processed_path']\n",
    "group_columns = ['diagnosis']\n",
    "df = df[group_columns + feat_keys].copy()\n",
    "\n",
    "# Normalize all feature columns\n",
    "df = df.dropna()\n",
    "for col in feat_keys:\n",
    "    df[col] = df[col].apply(lambda x: str(ROOT / x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n",
    "    \n",
    "# Define all possible hyperparameters\n",
    "models = [resnet34_model, googlenet_model]\n",
    "batch_sizes = [24, 32]\n",
    "test_splits = [.2, .25]\n",
    "validation_splits = [.2, .25]\n",
    "skip_cats_opts = [\n",
    "    'pico',\n",
    "    'muelle',\n",
    "    'minimental']\n",
    "skip_cats_combos = sum([list(combinations(skip_cats_opts, i))\n",
    "                        for i in range(len(skip_cats_opts))], [])\n",
    "skip_cats_combos = [[]]\n",
    "\n",
    "# Initialize random number generator without seed to randomize hyperparamters\n",
    "rnd = np.random.RandomState()\n",
    "\n",
    "# Cross product all hyperparameters\n",
    "parameter_combinations = list(product(\n",
    "    models, batch_sizes, test_splits, validation_splits, skip_cats_combos))\n",
    "rnd.shuffle(parameter_combinations)\n",
    "\n",
    "target_label = 'SANO'\n",
    "target_column = 'diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bananas.core.mixins import HighDimensionalMixin\n",
    "from bananas.sampling.cross_validation import DataSplit\n",
    "from bananas.statistics import scoring\n",
    "from bananas.statistics.scoring import ScoringFunction\n",
    "from coconuts.learners.transfer_learning import TransferLearningModel, BaseNNClassifier\n",
    "\n",
    "# Store results in a list to display them later\n",
    "trial_results = []\n",
    "\n",
    "for model, batch_size, test_split, validation_split, skip_cats in tqdm(parameter_combinations, leave=False):\n",
    "\n",
    "    # Re-initialize seed every time\n",
    "    random_seed = 0\n",
    "\n",
    "    # Create a single feature containing all image data\n",
    "    mask = df['processed_path'].astype(str).apply(\n",
    "        lambda impath: any([('processed_path_%s' % cat) in impath for cat in skip_cats]))\n",
    "    image_loader = ImageAugmenterLoader(\n",
    "        df.loc[~mask, 'processed_path'].values,\n",
    "        resize=(3, 224, 224),\n",
    "        normalize=True,\n",
    "        convert='RGB')\n",
    "    features = [Feature(\n",
    "        image_loader,\n",
    "        kind=DataType.HIGH_DIMENSIOAL,\n",
    "        sample_size=10,\n",
    "        random_seed=random_seed)]\n",
    "\n",
    "    # Define target feature\n",
    "    target_feature = Feature(\n",
    "        (df[target_column] == target_label).values, random_seed=random_seed)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Build dataset, making sure that we have a left-out validation subset\n",
    "        dataset = DataSet(\n",
    "            features,\n",
    "            name=target_label,\n",
    "            target=target_feature,\n",
    "            random_seed=random_seed,\n",
    "            batch_size=batch_size,\n",
    "            test_split=test_split,\n",
    "            validation_split=validation_split)\n",
    "\n",
    "        # Compute test class balance to tell what minimum accuracy we should beat\n",
    "        test_idx = dataset.sampler.subsamplers[DataSplit.VALIDATION].data\n",
    "        test_classes = target_feature[test_idx]\n",
    "        test_class_balance = sum(test_classes) / len(test_classes)\n",
    "\n",
    "        # Rebuild dataset unless test class balance is within 5% of ground truth\n",
    "        true_class_balance = sum(target_feature[:] / len(target_feature))\n",
    "        if abs(test_class_balance - true_class_balance) < .05: break\n",
    "\n",
    "        # Keep changing the seed to avoid getting stuck\n",
    "        random_seed += 1\n",
    "\n",
    "    # Instantiate learner using pre-trained model\n",
    "    learner = TransferLearningModel(\n",
    "        model,\n",
    "        freeze_base_model=True,\n",
    "        scoring_function=ScoringFunction.ACCURACY) \\\n",
    "        .apply_mixin(BaseNNClassifier, HighDimensionalMixin)\n",
    "\n",
    "    # Train learner using train dataset\n",
    "    learner.train(dataset.input_fn, progress=True, max_steps=200)\n",
    "\n",
    "    # Test learner predictions using left-out dataset\n",
    "    # We have to do it one datapoint at a time instead of in batch to prevent overflow\n",
    "    yl, ylt = [], []\n",
    "    for i in tqdm(test_idx, leave=False):\n",
    "        X, y = dataset[i:i+1]\n",
    "        y = learner.label_encoder_.transform(y)\n",
    "        y_ = learner.predict_proba(X)\n",
    "        yl.append(y[0])\n",
    "        ylt.append(y_[0])\n",
    "    y, y_ = yl, ylt\n",
    "    score_auroc = scoring.score_auroc(y, y_)\n",
    "    score_accuracy = scoring.score_accuracy(y, y_)\n",
    "    score_precision = scoring.score_precision(y, y_)\n",
    "    score_recall = scoring.score_recall(y, y_)\n",
    "\n",
    "    # Store trial results\n",
    "    naive_accuracy = max(test_class_balance, 1 - test_class_balance)\n",
    "    trial_results.append({\n",
    "        'Model': model.__class__.__name__,\n",
    "        'Subset splits': (test_split, validation_split),\n",
    "        'Skipped categories': ', '.join(skip_cats),\n",
    "        'Batch size': batch_size,\n",
    "        'Δ Naive Classifier': score_accuracy - naive_accuracy,\n",
    "        'Accuracy': score_accuracy,\n",
    "        'Precision': score_precision,\n",
    "        'Recall': score_recall,\n",
    "        'Area under ROC': score_auroc,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subset splits</th>\n",
       "      <th>Skipped categories</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Δ Naive Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area under ROC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GoogLeNet</th>\n",
       "      <td>(0.2, 0.2)</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.579753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoogLeNet</th>\n",
       "      <td>(0.2, 0.2)</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.488919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet</th>\n",
       "      <td>(0.2, 0.2)</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.607056</td>\n",
       "      <td>0.504059</td>\n",
       "      <td>0.469276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet</th>\n",
       "      <td>(0.2, 0.2)</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.504755</td>\n",
       "      <td>0.255623</td>\n",
       "      <td>0.508330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Subset splits Skipped categories  Batch size  Δ Naive Classifier  \\\n",
       "Model                                                                        \n",
       "GoogLeNet    (0.2, 0.2)                             24            0.064935   \n",
       "GoogLeNet    (0.2, 0.2)                             32           -0.038961   \n",
       "ResNet       (0.2, 0.2)                             24            0.019481   \n",
       "ResNet       (0.2, 0.2)                             32            0.012987   \n",
       "\n",
       "           Accuracy  Precision    Recall  Area under ROC  \n",
       "Model                                                     \n",
       "GoogLeNet  0.590909   0.400000  0.098765        0.579753  \n",
       "GoogLeNet  0.487013   0.253521  0.222222        0.488919  \n",
       "ResNet     0.545455   0.607056  0.504059        0.469276  \n",
       "ResNet     0.538961   0.504755  0.255623        0.508330  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(trial_results) \\\n",
    "    .set_index('Model') \\\n",
    "    .groupby(level=0, group_keys=False) \\\n",
    "    .apply(lambda x: x.sort_values('Accuracy', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
